{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monkrus/emotion_analyzer/blob/main/emotion_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following code analyzes the facial expression of the attached image. Run it and upload the image/s below the code.**"
      ],
      "metadata": {
        "id": "ffxaVN4QG2WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai pillow\n",
        "\n",
        "# detect facial expression of the attached images\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Configure the API key\n",
        "api_key = userdata.get('GEMINI_API_KEY')\n",
        "if not api_key:\n",
        "    print(\"Please add your API key to Colab's secrets manager with the name 'GOOGLE_API_KEY'\")\n",
        "    api_key = input(\"Or enter your API key here: \")\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Initialize the model\n",
        "model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "\n",
        "def analyze_facial_expression(image):\n",
        "    # Prepare the prompt\n",
        "    prompt = \"\"\"\n",
        "    Analyze this image and determine the facial expression of the person.\n",
        "    Categorize it as one of the following: happy, sad, angry, surprised, neutral, or other.\n",
        "    If 'other', specify what it might be.\n",
        "    Also, provide a brief explanation of why you chose that category.\n",
        "    Finally, estimate the confidence level of your analysis (low, medium, high).\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate content\n",
        "    response = model.generate_content([prompt, image])\n",
        "\n",
        "    # Print the response\n",
        "    print(response.text)\n",
        "\n",
        "# File upload widget\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process each uploaded file\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"Analyzing {filename}:\")\n",
        "    image = Image.open(io.BytesIO(uploaded[filename]))\n",
        "    analyze_facial_expression(image)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Optional: Analyze an image from a URL\n",
        "def analyze_image_from_url(url):\n",
        "    from urllib.request import urlopen\n",
        "    from PIL import Image\n",
        "\n",
        "    with urlopen(url) as response:\n",
        "        image = Image.open(response)\n",
        "\n",
        "    print(f\"Analyzing image from URL: {url}\")\n",
        "    analyze_facial_expression(image)\n",
        "\n",
        "# Uncomment and modify the line below to analyze an image from a URL\n",
        "# analyze_image_from_url(\"https://example.com/path/to/image.jpg\")"
      ],
      "metadata": {
        "id": "f9yvseu0PKmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following code analyzes the facial expression of the attached video. Run it and upload the video/s below the code. (variant 1)**"
      ],
      "metadata": {
        "id": "Km5AFDQQH8l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have the required libraries installed\n",
        "!pip install google-generativeai pillow opencv-python-headless\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "from PIL import Image\n",
        "import io\n",
        "import cv2\n",
        "import tempfile\n",
        "import time\n",
        "\n",
        "\n",
        "# Configure the API key\n",
        "api_key = userdata.get('GEMINI_API_KEY')\n",
        "if not api_key:\n",
        "    print(\"Please add your API key to Colab's secrets manager with the name 'GOOGLE_API_KEY'\")\n",
        "    api_key = input(\"Or enter your API key here: \")\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Initialize the model\n",
        "model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "\n",
        "def analyze_facial_expression(image):\n",
        "    # Prepare the prompt\n",
        "    prompt = \"\"\"\n",
        "    Analyze this image and determine the facial expression of the person.\n",
        "    Categorize it as one of the following: happy, sad, angry, surprised, neutral, or other.\n",
        "    If 'other', specify what it might be.\n",
        "    Also, provide a brief explanation of why you chose that category.\n",
        "    Finally, estimate the confidence level of your analysis (low, medium, high).\n",
        "    \"\"\"\n",
        "\n",
        "    # Retry mechanism for handling rate limits\n",
        "    retries = 5\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            # Generate content\n",
        "            response = model.generate_content([prompt, image])\n",
        "            # Print the response\n",
        "            print(response.text)\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e):  # Check for rate limit error\n",
        "                delay = min(2**i, 30)  # Exponential backoff with a maximum delay of 30 seconds\n",
        "                print(f\"Rate limit exceeded, retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "                return False\n",
        "    return False\n",
        "\n",
        "# File upload widget\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process each uploaded video file\n",
        "for filename in uploaded.keys():\n",
        "    if filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
        "        print(f\"Analyzing {filename}:\")\n",
        "\n",
        "        # Save the uploaded video to a temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as temp_video_file:\n",
        "            temp_video_file.write(uploaded[filename])\n",
        "            temp_video_file.flush()\n",
        "            temp_video_path = temp_video_file.name\n",
        "\n",
        "        video_capture = cv2.VideoCapture(temp_video_path)\n",
        "\n",
        "        frame_count = 0\n",
        "        frame_rate = int(video_capture.get(cv2.CAP_PROP_FPS))  # Get the frame rate of the video\n",
        "        sample_rate = frame_rate * 5  # Analyze one frame every 5 seconds\n",
        "\n",
        "        while video_capture.isOpened():\n",
        "            ret, frame = video_capture.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_count % sample_rate == 0:\n",
        "                # Convert the frame to PIL Image\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                image = Image.fromarray(frame_rgb)\n",
        "\n",
        "                print(f\"Analyzing frame {frame_count}:\")\n",
        "                if analyze_facial_expression(image):\n",
        "                    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "                else:\n",
        "                    break  # Stop processing if an error occurs\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        video_capture.release()\n",
        "    else:\n",
        "        print(f\"Unsupported file format: {filename}\")\n"
      ],
      "metadata": {
        "id": "W1R6yD5NBMhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following code analyzes the facial expression of the attached video.Run it and upload the video/s below the code.(variant 2)**"
      ],
      "metadata": {
        "id": "v-YBFBxMIkuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have the required libraries installed\n",
        "!pip install google-generativeai pillow opencv-python-headless\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "from PIL import Image\n",
        "import io\n",
        "import cv2\n",
        "import tempfile\n",
        "import time\n",
        "\n",
        "# Configure the API key\n",
        "api_key = userdata.get('GEMINI_API_KEY')\n",
        "if not api_key:\n",
        "    print(\"Please add your API key to Colab's secrets manager with the name 'GOOGLE_API_KEY'\")\n",
        "    api_key = input(\"Or enter your API key here: \")\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Initialize the model\n",
        "model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "\n",
        "def analyze_facial_expression(image):\n",
        "    # Prepare the prompt\n",
        "    prompt = \"\"\"\n",
        "    Analyze this image and determine the facial expression of the person.\n",
        "    Categorize it as one of the following: happy, sad, angry, surprised, neutral, or other.\n",
        "    If 'other', specify what it might be.\n",
        "    Also, provide a brief explanation of why you chose that category.\n",
        "    Finally, estimate the confidence level of your analysis (low, medium, high).\n",
        "    \"\"\"\n",
        "\n",
        "    # Retry mechanism for handling rate limits and internal server errors\n",
        "    retries = 5\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            # Generate content\n",
        "            response = model.generate_content([prompt, image])\n",
        "            # Print the response\n",
        "            print(response.text)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e):  # Check for rate limit error\n",
        "                delay = min(2**i, 30)  # Exponential backoff with a maximum delay of 30 seconds\n",
        "                print(f\"Rate limit exceeded, retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "            elif \"500\" in str(e):  # Check for internal server error\n",
        "                delay = min(2**i, 30)  # Exponential backoff with a maximum delay of 30 seconds\n",
        "                print(f\"Internal server error, retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "                return None\n",
        "    return None\n",
        "\n",
        "# File upload widget\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process each uploaded video file\n",
        "for filename in uploaded.keys():\n",
        "    if filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
        "        print(f\"Analyzing {filename}:\")\n",
        "\n",
        "        # Save the uploaded video to a temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as temp_video_file:\n",
        "            temp_video_file.write(uploaded[filename])\n",
        "            temp_video_file.flush()\n",
        "            temp_video_path = temp_video_file.name\n",
        "\n",
        "        video_capture = cv2.VideoCapture(temp_video_path)\n",
        "\n",
        "        frame_count = 0\n",
        "        frame_rate = int(video_capture.get(cv2.CAP_PROP_FPS))  # Get the frame rate of the video\n",
        "        sample_rate = frame_rate * 5  # Analyze one frame every 5 seconds\n",
        "\n",
        "        while video_capture.isOpened():\n",
        "            ret, frame = video_capture.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_count % sample_rate == 0:\n",
        "                # Convert the frame to PIL Image\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                image = Image.fromarray(frame_rgb)\n",
        "\n",
        "                print(f\"Analyzing frame {frame_count}:\")\n",
        "                if analyze_facial_expression(image):\n",
        "                    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "                else:\n",
        "                    break  # Stop processing if an error occurs\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        video_capture.release()\n",
        "    else:\n",
        "        print(f\"Unsupported file format: {filename}\")\n"
      ],
      "metadata": {
        "id": "VdNAWoh75qPm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}